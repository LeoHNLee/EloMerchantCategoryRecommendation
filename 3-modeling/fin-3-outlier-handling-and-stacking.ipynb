{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pygam import LinearGAM, s, f\n",
    "\n",
    "import optuna\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedShuffleSplit as SSsplit\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "def rmse(pred, true) : return np.sqrt(mse(true, pred))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = '../dataset/fin/'\n",
    "write_path = '../dataset/result/'\n",
    "train = pd.read_csv(read_path+'train_fe.csv')\n",
    "test = pd.read_csv(read_path+'test_fe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3a32ab878e4ea7aeecb5e91b833923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it proper file name? : test_fe.csv\n",
      "is it proper file name? : train_fe.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(read_path)\n",
    "newFiles = []\n",
    "histFiles = []\n",
    "transFiles = []\n",
    "isFile = re.compile(r'.*[.]csv')\n",
    "isNew = re.compile(r'.*_new[.]csv')\n",
    "isHist = re.compile(r'.*_hist[.]csv')\n",
    "isTrans = re.compile(r'.*_trans[.]csv')\n",
    "for file in tqdm(files):\n",
    "    if re.match(isFile, file):\n",
    "        locals()[file[:-4]] = pd.read_csv(read_path+file)\n",
    "        if re.match(isNew, file): newFiles.append(file[:-4])\n",
    "        elif re.match(isHist, file): histFiles.append(file[:-4])\n",
    "        elif re.match(isTrans, file): transFiles.append(file[:-4])\n",
    "        else : print('is it proper file name? : {}'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempCols = ['merchant_try_'+col if col!='card_id' else col for col in locals()['mertry_trans'].columns.tolist()]\n",
    "locals()['mertry_trans'].columns = tempCols\n",
    "tempCols = ['merchant_visit_'+col if col!='card_id' else col for col in locals()['mervisit_trans'].columns.tolist()]\n",
    "locals()['mervisit_trans'].columns = tempCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fe607d5c754027922498d7af62378b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_trans = train\n",
    "transFiles.remove('sm_test_trans',)\n",
    "for file in tqdm(transFiles):\n",
    "    train_trans = train_trans.merge(locals()[file], how='left', on='card_id')\n",
    "    if train_trans.shape[0] != train.shape[0] : print('it is wrong : {} : {}'.format(train_trans.shape, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc82ce7578f447cadae2179fe6d1427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_trans = test\n",
    "transFiles.append('sm_test_trans')\n",
    "transFiles.remove('sm_train_trans',)\n",
    "for file in tqdm(transFiles):\n",
    "    test_trans = test_trans.merge(locals()[file], how='left', on='card_id')\n",
    "    if test_trans.shape[0] != test.shape[0] : print('it is wrong : {} : {}'.format(test_trans.shape, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123623, 6), (325540, 8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_test_trans.shape, regular_FE_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCols = pd.read_csv('../dataset/modelCols/trans_401.csv')['modelCols'].values.tolist()\n",
    "modelCols+=sm_test_trans.columns[1:].tolist()\n",
    "modelCols+=regular_FE_trans.columns[1:].tolist()\n",
    "\n",
    "catCols = []\n",
    "isFeature = re.compile(r'feature_[\\d]')\n",
    "isModeKey = re.compile(r'.*_modeKey')\n",
    "\n",
    "for col in modelCols:\n",
    "    if re.match(isFeature, col): catCols.append(col)\n",
    "    elif re.match(isModeKey, col): catCols.append(col)\n",
    "\n",
    "catCols2 = []\n",
    "for col in catCols:\n",
    "    if train_trans[col].isna().sum()==0:\n",
    "        catCols2.append(modelCols.index(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rate = test.shape[0]/(train.shape[0]+test.shape[0])\n",
    "split_y = train['outliers']\n",
    "SSspliter = SSsplit(3, split_rate)\n",
    "\n",
    "# train_trans2 = train_trans[modelCols].replace([np.inf, -np.inf], np.nan)\n",
    "# train_trans2 = train_trans2.dropna(axis = 1)\n",
    "for i, (train_index, test_index) in enumerate(SSspliter.split(train, split_y)):\n",
    "    locals()['x_train_'+str(i)] = train_trans[modelCols].iloc[train_index]\n",
    "    locals()['x_validate_'+str(i)] = train_trans[modelCols].iloc[test_index]\n",
    "    locals()['y_train_'+str(i)] = train_trans['target'].iloc[train_index]\n",
    "    locals()['y_validate_'+str(i)] = train_trans['target'].iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6180e99b2fdd4e8db21c794cf23e07d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : 3.196229964215437 : 3.6811556138959425\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 935, \n",
    "          'max_depth': 245, \n",
    "          'learning_rate': 0.040630726310134826, \n",
    "          'num_estimators': 1436, \n",
    "          'subsample_for_bin': 6342, \n",
    "          'min_split_gain': 0.0004120715698725839, \n",
    "          'min_child_samples': 200, \n",
    "          'reg_labmda': 0.30042871016116973, \n",
    "          'drop_rate': 0.3708866605608058, \n",
    "          'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_threads': 8,\n",
    "    }\n",
    "train_score = 0\n",
    "validate_score = 0\n",
    "for i in tqdm(range(3)):\n",
    "    lgb_data = lgb.Dataset(globals()['x_train_'+str(i)], label = globals()['y_train_'+str(i)].values, categorical_feature=catCols)\n",
    "    bst = lgb.train(params, lgb_data)\n",
    "    locals()['lgb_pred_'+str(i)] = bst.predict(globals()['x_train_'+str(i)])\n",
    "    locals()['lgb_validate_'+str(i)] = bst.predict(globals()['x_validate_'+str(i)])\n",
    "    train_score += rmse(locals()['lgb_pred_'+str(i)], globals()['y_train_'+str(i)])\n",
    "    validate_score += rmse(locals()['lgb_validate_'+str(i)], globals()['y_validate_'+str(i)])\n",
    "print('socres', train_score/3, validate_score/3, sep=' : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08afe792be114e31b1951f91f0f13906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : 3.196229964215437 : 3.6811556138959425\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 935, \n",
    "          'max_depth': 245, \n",
    "          'learning_rate': 0.040630726310134826, \n",
    "          'num_estimators': 1000, \n",
    "          'subsample_for_bin': 6342, \n",
    "          'min_split_gain': 0.0004120715698725839, \n",
    "          'min_child_samples': 200, \n",
    "          'reg_labmda': 0.30042871016116973, \n",
    "          'drop_rate': 0.3708866605608058, \n",
    "          'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_threads': 8,\n",
    "    }\n",
    "train_score = 0\n",
    "validate_score = 0\n",
    "for i in tqdm(range(3)):\n",
    "    lgb_data = lgb.Dataset(globals()['x_train_'+str(i)], label = globals()['y_train_'+str(i)].values, categorical_feature=catCols)\n",
    "    bst = lgb.train(params, lgb_data)\n",
    "    locals()['lgb_pred_'+str(i)] = bst.predict(globals()['x_train_'+str(i)])\n",
    "    locals()['lgb_validate_'+str(i)] = bst.predict(globals()['x_validate_'+str(i)])\n",
    "    train_score += rmse(locals()['lgb_pred_'+str(i)], globals()['y_train_'+str(i)])\n",
    "    validate_score += rmse(locals()['lgb_validate_'+str(i)], globals()['y_validate_'+str(i)])\n",
    "print('socres', train_score/3, validate_score/3, sep=' : ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e20a1b5e2bb4588a1b6f2ec756ba3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : 3.3547971798718113 : 3.7101222066304764\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=900,\n",
    "              importance_type='gain',\n",
    "              n_jobs=8,  \n",
    "              silent=True, \n",
    "              objective='reg:linear',)\n",
    "train_score = 0\n",
    "validate_score = 0\n",
    "for i in tqdm(range(3)):\n",
    "    model.fit(globals()['x_train_'+str(i)], globals()['y_train_'+str(i)].values)\n",
    "    locals()['xgb_pred_'+str(i)] = model.predict(globals()['x_train_'+str(i)])\n",
    "    locals()['xgb_validate_'+str(i)] = model.predict(globals()['x_validate_'+str(i)])\n",
    "    train_score += rmse(locals()['xgb_pred_'+str(i)], globals()['y_train_'+str(i)])\n",
    "    validate_score += rmse(locals()['xgb_validate_'+str(i)], globals()['y_validate_'+str(i)])\n",
    "print('socres', train_score/3, validate_score/3, sep=' : ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7164f5955a4b51aced0aef2ec6cac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : :3.5310458737970336:3.68123711406974\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations=878, learning_rate=0.042356140476210384,\n",
    "#                         depth=trial.suggest_int('depth', 3, 400),\n",
    "                        silent=True,\n",
    "#                         early_stopping_rounds=10,\n",
    "                        loss_function='RMSE',\n",
    "                        thread_count=8,)\n",
    "train_score = 0\n",
    "validate_score = 0\n",
    "for i in tqdm(range(3)):\n",
    "    train_pool = Pool(globals()['x_train_'+str(i)], globals()['y_train_'+str(i)].values, cat_features=catCols2)\n",
    "    test_pool = Pool(globals()['x_validate_'+str(i)], cat_features=catCols2) \n",
    "    model.fit(train_pool, silent=True)\n",
    "    locals()['cat_pred_'+str(i)] = model.predict(train_pool)\n",
    "    locals()['cat_validate_'+str(i)] = model.predict(test_pool)\n",
    "    train_score += rmse(locals()['cat_pred_'+str(i)], globals()['y_train_'+str(i)])\n",
    "    validate_score += rmse(locals()['cat_validate_'+str(i)], globals()['y_validate_'+str(i)])\n",
    "print('socres : ', train_score/3, validate_score/3, sep=' : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27691966a7904573b7afb59e0fd6526e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres :  : 3.457500047665159 : 3.6805167552495632\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostRegressor(iterations=1078, learning_rate=0.052356140476210384,\n",
    "#                         depth=trial.suggest_int('depth', 3, 400),\n",
    "                        silent=True,\n",
    "#                         early_stopping_rounds=10,\n",
    "                        loss_function='RMSE',\n",
    "                        thread_count=8,)\n",
    "train_score = 0\n",
    "validate_score = 0\n",
    "for i in tqdm(range(3)):\n",
    "    train_pool = Pool(globals()['x_train_'+str(i)], globals()['y_train_'+str(i)].values, cat_features=catCols2)\n",
    "    test_pool = Pool(globals()['x_validate_'+str(i)], cat_features=catCols2) \n",
    "    model.fit(train_pool, silent=True)\n",
    "    locals()['cat_pred_'+str(i)] = model.predict(train_pool)\n",
    "    locals()['cat_validate_'+str(i)] = model.predict(test_pool)\n",
    "    train_score += rmse(locals()['cat_pred_'+str(i)], globals()['y_train_'+str(i)])\n",
    "    validate_score += rmse(locals()['cat_validate_'+str(i)], globals()['y_validate_'+str(i)])\n",
    "print('socres : ', train_score/3, validate_score/3, sep=' : ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking + Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a006c34dcc3a436e84a2dc1d67dd98a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 0 fold ----------\n",
      "fin score :3.6716416514523296\n",
      "---------- 1 fold ----------\n",
      "fin score :3.680018198965752\n",
      "---------- 2 fold ----------\n",
      "fin score :3.669020747529061\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(3)):\n",
    "    print('-'*10, str(i), 'fold', '-'*10)\n",
    "    pred = (locals()['lgb_validate_'+str(i)] + locals()['cat_validate_'+str(i)] + locals()['xgb_validate_'+str(i)])/3\n",
    "    print('fin score', rmse(pred, locals()['y_validate_'+str(i)].values), sep=' :' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859482f192524714a65625b9255f8fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 0 fold ----------\n",
      "train score : 3.1941357686678176 : 3.3569454649697255 : 3.4500180816402426\n",
      "validate score : 3.6803091602683757 : 3.710736799020011 : 3.6755508261961336\n",
      "linear score : 3.700116778790319 : 3.700116778790319 : 3.700116778790319 : 3.700116778790319\n",
      "fin score : 3.700116778790319\n",
      "fin score : 3.700116778790319\n",
      "---------- 1 fold ----------\n",
      "train score : 3.1921141030482763 : 3.3518444847242046 : 3.4601880103823457\n",
      "validate score : 3.687976903054129 : 3.7150565571580563 : 3.6893007498241457\n",
      "linear score : 3.709841499363369 : 3.709841499363369 : 3.709841499363369 : 3.709841499363369\n",
      "fin score : 3.709841499363369\n",
      "fin score : 3.709841499363369\n",
      "---------- 2 fold ----------\n",
      "train score : 3.2024400209302177 : 3.3556015899215033 : 3.46229405097289\n",
      "validate score : 3.6751807783653216 : 3.7045732637133617 : 3.67669868972841\n",
      "linear score : 3.6891150775985415 : 3.6891150775985415 : 3.6891150775985415 : 3.6891150775985415\n",
      "fin score : 3.6891150775985415\n",
      "fin score : 3.6891150775985415\n",
      "Wall time: 238 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ela = ElasticNet()\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "linear = LinearRegression()\n",
    "for i in tqdm(range(3)):\n",
    "    print('-'*10, str(i), 'fold', '-'*10)\n",
    "    preds = []\n",
    "    preds.append(locals()['lgb_pred_'+str(i)])\n",
    "    preds.append(locals()['xgb_pred_'+str(i)])\n",
    "    preds.append(locals()['cat_pred_'+str(i)])\n",
    "    preds = np.array(preds).T\n",
    "    print('train score', rmse(locals()['lgb_pred_'+str(i)], locals()['y_train_'+str(i)].values),\n",
    "          rmse(locals()['xgb_pred_'+str(i)], locals()['y_train_'+str(i)].values),\n",
    "          rmse(locals()['cat_pred_'+str(i)], locals()['y_train_'+str(i)].values), sep=' : ')\n",
    "\n",
    "    ela.fit(preds, locals()['y_train_'+str(i)].values)\n",
    "    lasso.fit(preds, locals()['y_train_'+str(i)].values)\n",
    "    ridge.fit(preds, locals()['y_train_'+str(i)].values)\n",
    "    linear.fit(preds, locals()['y_train_'+str(i)].values)\n",
    "    \n",
    "    validate = []\n",
    "    validate.append(locals()['lgb_validate_'+str(i)])\n",
    "    validate.append(locals()['xgb_validate_'+str(i)])\n",
    "    validate.append(locals()['cat_validate_'+str(i)])\n",
    "    validate = np.array(validate).T\n",
    "    print('validate score', rmse(locals()['lgb_validate_'+str(i)], locals()['y_validate_'+str(i)].values),\n",
    "          rmse(locals()['xgb_validate_'+str(i)], locals()['y_validate_'+str(i)].values),\n",
    "          rmse(locals()['cat_validate_'+str(i)], locals()['y_validate_'+str(i)].values), sep=' : ')\n",
    "    \n",
    "    ela_pred = ela.predict(validate)\n",
    "    lasso_pred = ela.predict(validate)\n",
    "    ridge_pred = ela.predict(validate)\n",
    "    linear_pred = ela.predict(validate)\n",
    "    \n",
    "    ela_score = rmse(ela_pred, locals()['y_validate_'+str(i)].values)\n",
    "    lasso_score = rmse(lasso_pred, locals()['y_validate_'+str(i)].values)\n",
    "    ridge_score = rmse(ridge_pred, locals()['y_validate_'+str(i)].values)\n",
    "    linear_score = rmse(linear_pred, locals()['y_validate_'+str(i)].values)\n",
    "    print('linear score', ela_score, lasso_score, ridge_score, linear_score, sep=' : ')\n",
    "    \n",
    "    total_score = 40-ela_score-lasso_score-ridge_score-linear_score\n",
    "    fin_pred = (ela_pred*(10-ela_score)+lasso_pred*(10-lasso_score)+ridge_pred*(10-ridge_score)+linear_pred*(10-linear_score))/total_score\n",
    "    print('fin score', rmse(fin_pred, locals()['y_validate_'+str(i)].values), sep=' : ')\n",
    "    \n",
    "    fin_pred = (ela_pred+lasso_pred+ridge_pred+linear_pred)/4\n",
    "    print('fin score', rmse(fin_pred, locals()['y_validate_'+str(i)].values), sep=' : ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\basic.py:1184: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb socres : 3.1766619527037068\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 935, \n",
    "          'max_depth': 245, \n",
    "          'learning_rate': 0.040630726310134826, \n",
    "          'num_estimators': 1436, \n",
    "          'subsample_for_bin': 6342, \n",
    "          'min_split_gain': 0.0004120715698725839, \n",
    "          'min_child_samples': 200, \n",
    "          'reg_labmda': 0.30042871016116973, \n",
    "          'drop_rate': 0.3708866605608058, \n",
    "          'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_threads': 8,\n",
    "    }\n",
    "lgb_data = lgb.Dataset(train_trans[modelCols], label = train_trans['target'].values, categorical_feature=catCols)\n",
    "bst = lgb.train(params, lgb_data)\n",
    "lgb_train_pred = bst.predict(train_trans[modelCols])\n",
    "lgb_test_pred = bst.predict(test_trans[modelCols])\n",
    "print('lgb socres', rmse(lgb_train_pred, train_trans['target'].values), sep=' : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostRegressor(iterations=878, \n",
    "                          learning_rate=0.042356140476210384,\n",
    "                        silent=True,\n",
    "                        early_stopping_rounds=10,\n",
    "                        loss_function='RMSE',\n",
    "                        thread_count=8,)\n",
    "train_pool = Pool(train_trans[modelCols], train_trans['target'].values, cat_features=catCols2)\n",
    "test_pool = Pool(test_trans[modelCols], cat_features=catCols2) \n",
    "model.fit(train_pool, silent=True)\n",
    "cat_train_pred = model.predict(train_pool)\n",
    "cat_test_pred = model.predict(test_pool)\n",
    "# print('cat socres : ', rmse(train_pool, train_trans['target'].values), sep=' : ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : :3.461744869726393\n",
      "Wall time: 9min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = XGBRegressor(n_estimators=900,n_jobs=8,objective='reg:linear',)\n",
    "model.fit(train_trans[modelCols], train_trans['target'].values)\n",
    "xgb_train_pred = model.predict(train_trans[modelCols])\n",
    "xgb_test_pred = model.predict(test_trans[modelCols])\n",
    "print('socres : ', rmse(xgb_train_pred, train_trans['target'].values), sep=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\basic.py:1184: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb socres : 0.09733246894934568\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 10, \n",
    "          'max_depth': 194, \n",
    "          'learning_rate': 0.04398858791379669, \n",
    "          'num_estimators': 757, \n",
    "          'subsample_for_bin': 9697, \n",
    "          'min_split_gain': 0.0003616307235817724, \n",
    "          'min_child_samples': 50, \n",
    "#           'reg_labmda': 0.30042871016116973, \n",
    "          'drop_rate': 0.3856214959567157, \n",
    "          'boosting': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_threads': 8,\n",
    "    }\n",
    "lgb_data = lgb.Dataset(train_trans[modelCols], label = train_trans['outliers'].values, categorical_feature=catCols)\n",
    "bst = lgb.train(params, lgb_data)\n",
    "lgb_train_pred_outlier = bst.predict(train_trans[modelCols])\n",
    "lgb_test_pred_outlier = bst.predict(test_trans[modelCols])\n",
    "print('lgb socres', rmse(lgb_train_pred_outlier, train_trans['outliers'].values), sep=' : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : :0.0993498479611383\n",
      "Wall time: 8min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = XGBClassifier(n_estimators=700,n_jobs=8,objective='binary:logistic',)\n",
    "model.fit(train_trans[modelCols], train_trans['outliers'].values)\n",
    "xgb_train_pred_outlier = model.predict(train_trans[modelCols])\n",
    "xgb_test_pred_outlier = model.predict(test_trans[modelCols])\n",
    "print('socres : ', rmse(xgb_train_pred_outlier, train_trans['outliers'].values), sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostClassifier(iterations=878, \n",
    "                          learning_rate=0.042356140476210384,\n",
    "                        silent=True,\n",
    "#                         early_stopping_rounds=10,\n",
    "                        loss_function='Logloss',\n",
    "                        thread_count=8,)\n",
    "train_pool = Pool(train_trans[modelCols], train_trans['outliers'].values, cat_features=catCols2)\n",
    "test_pool = Pool(test_trans[modelCols], cat_features=catCols2) \n",
    "model.fit(train_pool, silent=True)\n",
    "cat_train_pred_outlier = model.predict(train_pool)\n",
    "cat_test_pred_outlier = model.predict(test_pool)\n",
    "# print('cat socres : ', rmse(train_pool, train_trans['target'].values), sep=' : ') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb socres : 1.4239913408255898\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': 236, \n",
    "          'max_depth': 348, \n",
    "          'learning_rate': 0.051166673097082824, \n",
    "          'num_estimators': 1315, \n",
    "          'subsample_for_bin': 18011, \n",
    "          'min_split_gain': 0.0008656977198460191, \n",
    "          'min_child_samples': 165, \n",
    "          'reg_labmda': 0.16127074250244233, \n",
    "          'drop_rate': 0.49499130640699673, \n",
    "          'boosting': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'num_threads': 8,\n",
    "    }\n",
    "lgb_data = lgb.Dataset(train_trans[train_trans['outliers']==0][modelCols], label = train_trans[train_trans['outliers']==0]['target'].values, categorical_feature=catCols)\n",
    "bst = lgb.train(params, lgb_data)\n",
    "lgb_train_pred_pure = bst.predict(train_trans[train_trans['outliers']==0][modelCols])\n",
    "lgb_test_pred_pure = bst.predict(test_trans[modelCols])\n",
    "print('lgb socres', rmse(lgb_train_pred_pure, train_trans[train_trans['outliers']==0]['target'].values), sep=' : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostRegressor(iterations=1078, \n",
    "                          learning_rate=0.052356140476210384,\n",
    "                        silent=True,\n",
    "                        early_stopping_rounds=10,\n",
    "                        loss_function='RMSE',\n",
    "                        thread_count=8,)\n",
    "train_pool = Pool(train_trans[train_trans['outliers']==0][modelCols], train_trans[train_trans['outliers']==0]['target'].values, cat_features=catCols2)\n",
    "test_pool = Pool(test_trans[modelCols], cat_features=catCols2) \n",
    "model.fit(train_pool, silent=True)\n",
    "cat_train_pred_pure = model.predict(train_pool)\n",
    "cat_test_pred_pure = model.predict(test_pool)\n",
    "# print('cat socres : ', rmse(train_pool, train_trans['target'].values), sep=' : ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socres : :1.5205947145641507\n",
      "Wall time: 11min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = XGBRegressor(n_estimators=1100,n_jobs=8,objective='reg:linear',)\n",
    "model.fit(train_trans[train_trans['outliers']==0][modelCols], train_trans[train_trans['outliers']==0]['target'].values)\n",
    "xgb_train_pred_pure = model.predict(train_trans[train_trans['outliers']==0][modelCols])\n",
    "xgb_test_pred_pure = model.predict(test_trans[modelCols])\n",
    "print('socres : ', rmse(xgb_train_pred_pure, train_trans[train_trans['outliers']==0]['target'].values), sep=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf1 = RandomForestRegressor(n_estimators=1000, n_jobs=8,)\n",
    "\n",
    "rf1.fit(train_trans[modelCols], train_trans['target'])\n",
    "\n",
    "rf_train_pred = rf1.predict(train_trans[modelCols])\n",
    "rf_test_pred = rf1.predict(test_trans[modelCols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 블랜딩 한 다음에 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame(test_trans['card_id'])\n",
    "test_pred['pred'] = (lgb_test_pred+xgb_test_pred+cat_test_pred)/3\n",
    "test_pred['pure'] = (lgb_test_pred_pure+xgb_test_pred_pure+cat_test_pred_pure)/3\n",
    "test_pred['outlier'] = (lgb_test_pred_outlier+xgb_test_pred_outlier+cat_test_pred_outlier)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = test_pred.sort_values(by='outlier', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 치환 한 다음에 블랜딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pred(pred, outlier, pure):\n",
    "    ret = pd.DataFrame(train_trans['card_id'])\n",
    "    ret['pred'] = pred\n",
    "    ret['outlier'] = outlier\n",
    "    temp = pd.DataFrame(train_trans[train_trans['outliers']==0]['card_id'])\n",
    "    temp['true'] = pure\n",
    "    ret = ret.merge(temp, how='left', on='card_id')\n",
    "#     ret['true'] = pure\n",
    "    return ret\n",
    "\n",
    "lgb_train_pred_all = merge_pred(lgb_train_pred, lgb_train_pred_outlier, lgb_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "xgb_train_pred_all = merge_pred(xgb_train_pred, xgb_train_pred_outlier, xgb_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "cat_train_pred_all = merge_pred(cat_train_pred, cat_train_pred_outlier, cat_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "\n",
    "# rf_train_pred_all = merge_pred(rf_train_pred, rf_train_pred_outlier, rf_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "# ela_train_pred_all = merge_pred(ela_train_pred, ela_train_pred_outlier, ela_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "# ridge_train_pred_all = merge_pred(ridge_train_pred, ridge_train_pred_outlier, ridge_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "# lasso_train_pred_all = merge_pred(lasso_train_pred, lasso_train_pred_outlier, lasso_train_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "\n",
    "def merge_pred(pred, outlier, pure):\n",
    "    ret = pd.DataFrame(test_trans['card_id'])\n",
    "    ret['pred'] = pred\n",
    "    ret['outlier'] = outlier\n",
    "    ret['true'] = pure\n",
    "    return ret\n",
    "\n",
    "lgb_test_pred_all = merge_pred(lgb_test_pred, lgb_test_pred_outlier, lgb_test_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "xgb_test_pred_all = merge_pred(xgb_test_pred, xgb_test_pred_outlier, xgb_test_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "cat_test_pred_all = merge_pred(cat_test_pred, cat_test_pred_outlier, cat_test_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "\n",
    "# rf_test_pred_all = merge_pred(rf_test_pred, rf_test_pred_outlier, rf_test_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "# ela_test_pred_all = merge_pred(ela_test_pred, ela_test_pred_outlier, ela_test_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "# ridge_test_pred_all = merge_pred(ridge_test_pred, ridge_test_pred_outlier, ridge_test_pred_pure).sort_values(by='outlier', ascending=False)\n",
    "# lasso_test_pred_all = merge_pred(lasso_test_pred, lasso_test_pred_outlier, lasso_test_pred_pure).sort_values(by='outlier', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cut_off= int(train.shape[0]*.2)\n",
    "lgb_train_pred_all['target'] = np.append(lgb_train_pred_all['pred'][:cut_off], lgb_train_pred_all['true'][cut_off:])\n",
    "xgb_train_pred_all['target'] = np.append(xgb_train_pred_all['pred'][:cut_off], xgb_train_pred_all['true'][cut_off:])\n",
    "cat_train_pred_all['target'] = np.append(cat_train_pred_all['pred'][:cut_off], cat_train_pred_all['true'][cut_off:])\n",
    "\n",
    "# rf_train_pred_all['target'] = np.append(rf_train_pred_all['outlier'][:cut_off], rf_train_pred_all['pred'][cut_off:])\n",
    "# ela_train_pred_all['target'] = np.append(ela_train_pred_all['outlier'][:cut_off], ela_train_pred_all['pred'][cut_off:])\n",
    "# lasso_train_pred_all['target'] = np.append(lasso_train_pred_all['outlier'][:cut_off], lasso_train_pred_all['pred'][cut_off:])\n",
    "# ridge_train_pred_all['target'] = np.append(ridge_train_pred_all['outlier'][:cut_off], ridge_train_pred_all['pred'][cut_off:])\n",
    "\n",
    "cut_off= int(test.shape[0]*.2)\n",
    "lgb_test_pred_all['target'] = np.append(lgb_test_pred_all['pred'][:cut_off], lgb_test_pred_all['true'][cut_off:])\n",
    "xgb_test_pred_all['target'] = np.append(xgb_test_pred_all['pred'][:cut_off], xgb_test_pred_all['true'][cut_off:])\n",
    "cat_test_pred_all['target'] = np.append(cat_test_pred_all['pred'][:cut_off], cat_test_pred_all['true'][cut_off:])\n",
    "\n",
    "# rf_test_pred_all['target'] = np.append(rf_test_pred_all['outlier'][:cut_off], rf_test_pred_all['pred'][cut_off:])\n",
    "# ela_test_pred_all['target'] = np.append(ela_test_pred_all['outlier'][:cut_off], ela_test_pred_all['pred'][cut_off:])\n",
    "# lasso_test_pred_all['target'] = np.append(lasso_test_pred_all['outlier'][:cut_off], lasso_test_pred_all['pred'][cut_off:])\n",
    "# ridge_test_pred_all['target'] = np.append(ridge_test_pred_all['outlier'][:cut_off], ridge_test_pred_all['pred'][cut_off:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train_pred_all = lgb_train_pred_all.sort_values(by='card_id')\n",
    "xgb_train_pred_all = xgb_train_pred_all.sort_values(by='card_id')\n",
    "cat_train_pred_all = cat_train_pred_all.sort_values(by='card_id')\n",
    "\n",
    "# rf_train_pred_all = rf_train_pred_all.sort_values(by='card_id')\n",
    "# ela_train_pred_all = ela_train_pred_all.sort_values(by='card_id')\n",
    "# lasso_train_pred_all = lasso_train_pred_all.sort_values(by='card_id')\n",
    "# ridge_train_pred_all = ridge_train_pred_all.sort_values(by='card_id')\n",
    "\n",
    "lgb_test_pred_all = lgb_test_pred_all.sort_values(by='card_id')\n",
    "xgb_test_pred_all = xgb_test_pred_all.sort_values(by='card_id')\n",
    "cat_test_pred_all = cat_test_pred_all.sort_values(by='card_id')\n",
    "\n",
    "# rf_test_pred_all = rf_test_pred_all.sort_values(by='card_id')\n",
    "# ela_test_pred_all = ela_test_pred_all.sort_values(by='card_id')\n",
    "# lasso_test_pred_all = lasso_test_pred_all.sort_values(by='card_id')\n",
    "# ridge_test_pred_all = ridge_test_pred_all.sort_values(by='card_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-6fad594d9094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# ela.fit(preds, train_trans['target'].values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mlasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_trans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_trans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_trans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, check_input)\u001b[0m\n\u001b[0;32m    711\u001b[0m             X, y = check_X_y(X, y, accept_sparse='csc',\n\u001b[0;32m    712\u001b[0m                              \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                              copy=X_copied, multi_output=True, y_numeric=True)\n\u001b[0m\u001b[0;32m    714\u001b[0m             y = check_array(y, order='F', copy=False, dtype=X.dtype.type,\n\u001b[0;32m    715\u001b[0m                             ensure_2d=False)\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# ela = ElasticNet()\n",
    "lasso = Lasso()\n",
    "ridge = Ridge()\n",
    "linear = LinearRegression()\n",
    "      \n",
    "preds = []\n",
    "preds.append(lgb_train_pred_all['target'].values)\n",
    "preds.append(xgb_train_pred_all['target'].values)\n",
    "preds.append(cat_train_pred_all['target'].values)\n",
    "# preds.append(rf_train_pred_all['target'].values)\n",
    "# preds.append(ela_train_pred_all['target'].values)\n",
    "# preds.append(lasso_train_pred_all['target'].values)\n",
    "# preds.append(ridge_train_pred_all['target'].values)\n",
    "preds = np.array(preds).T\n",
    "\n",
    "# ela.fit(preds, train_trans['target'].values)\n",
    "lasso.fit(preds, train_trans['target'].values)\n",
    "ridge.fit(preds, train_trans['target'].values)\n",
    "linear.fit(preds, train_trans['target'].values)\n",
    "    \n",
    "validate = []\n",
    "validate.append(lgb_test_pred_all['target'].values)\n",
    "validate.append(xgb_test_pred_all['target'].values)\n",
    "validate.append(cat_test_pred_all['target'].values)\n",
    "# validate.append(rf_test_pred_all['target'].values)\n",
    "# validate.append(ela_test_pred_all['target'].values)\n",
    "# validate.append(lasso_test_pred_all['target'].values)\n",
    "# validate.append(ridge_test_pred_all['target'].values)\n",
    "validate = np.array(validate).T\n",
    "    \n",
    "# ela_pred = ela.predict(validate)\n",
    "lasso_pred = lasso.predict(validate)\n",
    "ridge_pred = ridge.predict(validate)\n",
    "linear_pred = linear.predict(validate)\n",
    "\n",
    "# fin_pred1 = (ela_pred*ela_score+lasso_pred*lasso_score+ridge_pred*ridge_score+linear_pred*linear_score)/total_score\n",
    "fin_pred2 = (lasso_pred+ridge_pred+linear_pred)/3\n",
    "# fin1_submission = submission(fin_pred1)\n",
    "# fin1_submission.to_csv(write_path+'20190227_linear_rate.csv', index=False)\n",
    "# fin2_submission = submission(fin_pred2)\n",
    "# fin2_submission.to_csv('../20190227_linear_uniform.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = (lgb_test_pred_all['target'].values+xgb_test_pred_all['target'].values+cat_test_pred_all['target'].values)/3\n",
    "# validate.append(rf_test_pred_all['target'].values)\n",
    "# validate.append(ela_test_pred_all['target'].values)\n",
    "# validate.append(lasso_test_pred_all['target'].values)\n",
    "# validate.append(ridge_test_pred_all['target'].values)\n",
    "# validate = np.array(validate).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off= int(test.shape[0]*.1)\n",
    "test_pred['target'] = np.append(test_pred['pred'][:cut_off], test_pred['pure'][cut_off:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(pred):\n",
    "    ret = pd.DataFrame(lgb_test_pred_all['card_id'])\n",
    "    ret['target'] = pred\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = pd.DataFrame(test_trans['card_id'])\n",
    "test_pred2['target'] = validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_blend = test_pred2[['card_id', 'target']].reset_index(drop=True)\n",
    "sub_blend.to_csv('../20190227_blend_fin.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
